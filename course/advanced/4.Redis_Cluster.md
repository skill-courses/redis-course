# Redis集群（Redis Cluster）

![redis-cluster](https://tva1.sinaimg.cn/large/008i3skNgy1gynyobc562j31hc0u0goe.jpg)

前面我们通过学习持久化，主从复制和哨兵机制，基本上就可以搭建一个比较强悍的Redis集群出来了，这个集群通常可以满足大部分的业务需求。比如并发量在10万/秒以内，存储内存在256G以内的业务应该是可以轻松应对了，但是如果你的业务需求比这个还要恐怖呢？比如百万级的并发量和大数据的需求呢？这个时候，我们就需要呼唤Redis Cluster出厂了！

## 集群概述

> Redis Cluster is a full mesh where every node is connected with every other node using a TCP connection.

Redis 集群是一个完整的网格，其中每个节点都使用 TCP 连接与每个其他节点连接。

Redis 集群为以下目标而设计：

* High performance and linear scalability up to 1000 nodes. There are no proxies, asynchronous replication is used, and no merge operations are performed on values.
* Acceptable degree of write safety: the system tries (in a best-effort way) to retain all the writes originating from clients connected with the majority of the master nodes. Usually there are small windows where acknowledged writes can be lost. Windows to lose acknowledged writes are larger when clients are in a minority partition.
* Availability: Redis Cluster is able to survive partitions where the majority of the master nodes are reachable and there is at least one reachable replica for every master node that is no longer reachable. Moreover using replicas migration, masters no longer replicated by any replica will receive one from a master which is covered by multiple replicas.

要实现上面的目标，首先要考虑数据的分布式存储：

## 数据分片

为了提高并发量和大量数据的存储，Redis Cluster使用数据分片的办法把数据分配到不同的节点；每个节点可以有自己的备份节点（一个或多个）。整个集群之上另有一个叫做Redis Sentinel的分布式组件用以提供更丰富的HA能力。

![redis-slice-data](https://tva1.sinaimg.cn/large/008i3skNgy1gynzigpxn3j30p20b70u2.jpg)

通常而言，实现数据分片有两种方式，一种是顺序分片，另一种是Hash分片。

* **顺序分片**：顾名思义，数据的顺序分片就是将数据按照一定的顺序分别放置在不同的节点上，每个节点承载的数据大体上一致。
* **Hash分片**：对数据取Hash值之后按照节点数进行取余(Hash(data) % node)，按照余数依次将其放置在不同的节点上。

![hash-slice](https://tva1.sinaimg.cn/large/008i3skNgy1gynzp2vcauj30yl0dijt2.jpg)

其优缺点和不同如下：

![hash-sort](https://tva1.sinaimg.cn/large/008i3skNgy1gynzs8by16j30mv0aat9y.jpg)

现在我们来思考另一个问题，对于上面两种分区，该如何实现弹性伸缩？即弹性扩容？

对于顺序分区来说，如果要添加一个节点，那么基本上对已经存在的节点的数据移动较少，比如对100条顺序分布在三个节点(0~33, 34~67, 68~100条)的数据，将其进行重新分段(分为四个段：0~25, 26~52, 53~78, 78~100)，对少数数据进行移动即可, 数据的移动量随着节点的数量成反比减少。

但是对于Hash分区而言，添加一个节点，需要移动的数据量就比较大了，通常保守估计在80%左右。所以，对于Hash分区的数据，为了降低数据的迁移量，通常采用**多倍扩容**的方法。

![mulitple-expanison](https://tva1.sinaimg.cn/large/008i3skNgy1gyp4lh3kn9j31l00u0n14.jpg)

然而，Redis Cluster在Hash分区的基础之上，提出了“虚拟槽”分区的概念：

## 虚拟槽分区

Redis Cluster使用`Slot`的概念：作为一个KV系统，它把每个key的值hash成`0 ~ 16383`之间的一个数。这个hash值被用来确定对应的数据存储在哪个节点中。集群中的每个节点都存储了一份类似路由表的东西，描述每个节点所拥有的 Slots；当用户请求一个不在本机的key的时候，它可以根据这个路由表找到正确的服务节点，然后回复给用户一个moved，告知用户正确的服务节点。

所以：
* slot = CRC16(key) % 16383；
* 是集群内数据管理和迁移的最小单位，保证数据管理的粒度易于管理；
* 每个节点都知道slot在集群中的分布，并能把对应信息回复给无法服务的请求。
* 节点之间保持Gossip通信

![redis-slot](https://tva1.sinaimg.cn/large/008i3skNgy1gyp518jcg3j30dw08c74r.jpg)

## 集群架构

![redis-cluster-architecture](https://tva1.sinaimg.cn/large/008i3skNgy1gyp5bva7b5j30fr0e20tm.jpg)

* 所有的redis节点之间通过Meet操作(PING-PONG 机制)进行联络, 内部使用二进制协议优化传输速度和带宽.
* 任何一个节点都是主备模式
* 节点的 fail 是通过集群中超过半数的节点检测失效时才生效.
* 客户端与 redis 节点直连,不需要中间 proxy 层.客户端不需要连接集群所有节点, 连接集群中任何一个可用节点即可，任何一个节点都能感知到其他节点存在
* redis-cluster 把所有的物理节点映射到[0-16383]slot 上,cluster 负责维护 node<->slot<->value

## 集群的扩容和缩容

当我们在特殊的情况下，比如双十一大促，这个时候我们以前的Redis集群可能无法满足突然的流量冲击，需要更多的节点来承担，这就需要扩容；当大促之后，流量回归正常，太多的节点会导致资源的浪费，所以我们需要对其进行缩容。所以，**集群伸缩的本质是槽和数据在节点之间的移动。**

### 扩容过程
一般情况下，我们通过以下步骤来实现集群的扩容：
1. 创建一个空的集群实例
2. 将此实例通过Meet操作添加到集群中
3. 给此新节点迁移数据，详细的流程如下：

![move-data](https://tva1.sinaimg.cn/large/008i3skNgy1gysmb9pij7j31780u041g.jpg)

### 缩容过程

与扩容过程相对，缩容过程也需要三步：

1. 下线迁移槽，如果此节点持有槽，迁移这些槽到其他节点即可。
2. 通知集群中其他节点忘记此节点
3. 关闭节点

整个过程如下：

![flex-container](https://tva1.sinaimg.cn/large/008i3skNgy1gysmhdmo8fj30uo0qwwfo.jpg)



